# Total cores in cluster. Used for calculating amount of distributed data partitions.
spark.global.cores=4

# Common parameters for Spark's driver
## Enables debug mode
spark.application.debug=false
## Suppress result output stream
spark.application.silent=false
## Enables internal Spark logging
spark.application.verbose=false
## Suppress saving new shingles into database
spark.application.no_save=false
## Local file for results' output
spark.application.output=
## Documents' ids for being checked, csv format. E.g.: 1,4,22,98
spark.application.documents=

# Database configuration
spark.db.supply.connection.driver=com.mysql.jdbc.Driver
spark.db.supply.connection.url=jdbc:mysql://192.168.1.1:3306/__thesis
spark.db.supply.connection.username=superuser
spark.db.supply.connection.password=585879

## Table with documents
database.supply.document.table=document
database.supply.document.primary_key=document_id

## Table with old shingles
database.supply.shingle.table=shingle
database.supply.shingle.primary_key=document_id

# Defines parsers for StringProcessManager. Should implement IProcessor<String> interface, full class name must be given.
parsing.processors=ua.edu.sumdu.dl.parsing.processor.TransliterateStringProcessor,ua.edu.sumdu.dl.parsing.processor.RemoveSpaceStringProcessor

# The size of shingle in ShingleAlgorithm
algorithm.shingles.shingle_size=4